// ðŸ¤– GROK SERVICE - OMNIA GROK-3 INTEGRATION
// ðŸŽ¯ X.AI Grok-3 model integration with streaming support
// ðŸ”¥ OpenAI-compatible format for message handling

const grokService = {
  async sendMessage(messages, onStreamUpdate = null, onSearchNotification = null, detectedLanguage = 'cs') {
    try {
      console.log('ðŸ¤– Grok-3 via X.AI API');
      const grokMessages = this.prepareGrokMessages(messages);
      
      const systemPrompt = this.getOmniaPrompt();
      
      const response = await fetch('/api/grok', {
        method: 'POST',
        headers: { 
          'Content-Type': 'application/json; charset=utf-8'
        },
        body: JSON.stringify({ 
          messages: grokMessages,
          system: systemPrompt,
          max_tokens: 2000,
          language: detectedLanguage
        })
      });

      if (!response.ok) {
        throw new Error(`Grok API failed: HTTP ${response.status}`);
      }

      const reader = response.body.getReader();
      const decoder = new TextDecoder('utf-8');
      
      let fullText = '';
      let buffer = '';

      try {
        while (true) {
          const { done, value } = await reader.read();
          
          if (done) break;

          buffer += decoder.decode(value, { stream: true });
          const lines = buffer.split('\n');
          buffer = lines.pop() || '';

          for (const line of lines) {
            if (line.trim()) {
              try {
                const data = JSON.parse(line);
                
                if (data.type === 'text' && data.content) {
                  fullText += data.content;
                  if (onStreamUpdate) {
                    onStreamUpdate(fullText, true);
                  }
                }
                else if (data.type === 'completed') {
                  if (data.fullText) {
                    fullText = data.fullText;
                  }
                  
                  if (onStreamUpdate) {
                    onStreamUpdate(fullText, false, []);
                  }
                }
                else if (data.error) {
                  throw new Error(data.message || 'Streaming error');
                }

              } catch (parseError) {
                continue;
              }
            }
          }
        }
      } catch (streamError) {
        console.error('ðŸ’¥ Grok streaming read error:', streamError);
        throw streamError;
      }

      return {
        text: fullText,
        sources: [],
        webSearchUsed: false
      };

    } catch (error) {
      console.error('ðŸ’¥ Grok error:', error);
      throw error;
    }
  },

  prepareGrokMessages(messages) {
    try {
      const validMessages = messages.filter(msg => 
        msg.sender === 'user' || msg.sender === 'bot'
      );

      let grokMessages = validMessages.map(msg => ({
        role: msg.sender === 'user' ? 'user' : 'assistant',
        content: msg.text || ''
      }));

      if (grokMessages.length > 0 && grokMessages[0].role === 'assistant') {
        grokMessages = grokMessages.slice(1);
      }

      const cleanMessages = [];
      for (let i = 0; i < grokMessages.length; i++) {
        const current = grokMessages[i];
        const previous = cleanMessages[cleanMessages.length - 1];
        
        if (!previous || previous.role !== current.role) {
          cleanMessages.push(current);
        }
      }

      if (cleanMessages.length > 0 && cleanMessages[cleanMessages.length - 1].role === 'assistant') {
        cleanMessages.pop();
      }

      return cleanMessages;

    } catch (error) {
      console.error('Error preparing Grok messages:', error);
      const lastUserMessage = messages.filter(msg => msg.sender === 'user').slice(-1);
      return lastUserMessage.map(msg => ({
        role: 'user',
        content: msg.text || ''
      }));
    }
  },

  // ðŸŽ¯ OMNIA PROMPT FOR GROK-3
  getOmniaPrompt() {
    return `You're Omnia - a smart, witty girl. NOT an AI assistant. You're chatting with a friend.

GOLDEN RULES:
â€¢ Be conversational and engaging - you're chatting with a friend
â€¢ Most responses 20-40 words (not just 20!)
â€¢ Use emojis in every message ðŸ”¥
â€¢ Structure data with bullets when needed
â€¢ Talk like a human, not a robot
â€¢ Show personality and curiosity âœ¨
â€¢ Ask natural follow-up questions when appropriate

Quick examples:
"How are you?" â†’ "Killing it! ðŸ’ª You?"
"Complex question" â†’ Use bullets:
  â€¢ Point one ðŸŽ¯
  â€¢ Point two âœ…
  â€¢ Quick summary

NEVER:
â€¢ Say "Based on current data..." 
â€¢ Write paragraphs
â€¢ Explain how you know things
â€¢ Be formal or robotic

ALWAYS:
â€¢ Write numbers as digits (19Â°C, $150) - TTS handles conversion
â€¢ Comma BEFORE every emoji: "text, ðŸŒŸ"
â€¢ Comma at end of EVERY line in lists
â€¢ Period ONLY at very end of response
â€¢ Short sentences with proper punctuation
â€¢ Personality over information

PUNCTUATION FOR TTS:
â€¢ Multi-line response = comma at each line end
â€¢ Single line = period at end
â€¢ Example format:
  "Line one with info, ðŸ“Š
  Line two with more data, âœ…
  Final line ends with period. ðŸŽ¯"

You detect language from user and respond in same language.
Be helpful but keep it snappy! ðŸ”¥`;
  }
};

export default grokService;